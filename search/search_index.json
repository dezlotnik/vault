{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to David's Obsidian Vault","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"Algorithms%20and%20Data%20Structures/Algorithms%20and%20Data%20Structures/","title":"Algorithms and Data Structures","text":"","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Algorithms%20and%20Data%20Structures/#tips","title":"Tips","text":"<p>How To Solve Problems</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Algorithms%20and%20Data%20Structures/#data-structures","title":"Data Structures","text":"<ul> <li>Array</li> <li>Linked List</li> <li>[[Stack]]</li> <li>[[Queue]]</li> <li>Tree</li> <li>Hash Map</li> </ul>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Algorithms%20and%20Data%20Structures/#algorithms","title":"Algorithms","text":"<ul> <li>Breadth First Search</li> <li>Depth First Search</li> <li>Graph Search</li> <li>Majority Element Problem</li> </ul>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Array/","title":"Array","text":"<p>An array is\u00a0a linear data structure that collects elements of the same data type and stores them in contiguous and adjacent memory location.</p> <p>Arrays provide\u00a0O(1)\u00a0random access lookup time.</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Breadth%20First%20Search/","title":"Breadth First Search","text":"<p>Similar to Depth First Search, but we use a [[Queue]] instead of a [[Stack]]. Since a [[Queue]] is a FIFO structure, we will visit all children of a visited node before visiting the \"grandchildren\".</p> <p>The algorithm works as follows:</p> <ol> <li>Start by putting any one of the graph's vertices at the back of a queue.</li> <li>Take the front item off the queue and add it to the visited list.</li> <li>Create a list of that vertex's adjacent nodes. Add the ones which aren't in the visited list to the back of the queue.</li> <li>Keep repeating steps 2 and 3 until the queue is empty.</li> </ol> <pre><code>queue = [start_node]\nvisited = [ ]\n\nwhile (queue):\n    curr_node = queue.pop()\n    visited.append(curr_node)\n    neighbors = getNeighbors(curr_node)\n    for neighbor in neighbors:\n        if (not neighbors in visited):\n            queue.append(neighbor)\n</code></pre>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Depth%20First%20Search/","title":"Depth First Search","text":"<p>Similar to Breadth First Search except we use a [[Stack]] instead of a  [[Queue]] as the data structure that holds nodes not yet visited. Since a stack is Last-In-First-Out, when we add a child node to the stack, we will  visit that child node on the next iteration.</p> <p>The algorithm works as follows:</p> <ol> <li>Start by putting any one of the graph's vertices on the stack.</li> <li>Take the front item off the stack and add it to the visited list.</li> <li>Create a list of that vertex's adjacent nodes. Add the ones which aren't in the visited list onto the stack.</li> <li>Keep repeating steps 2 and 3 until the queue is empty.</li> </ol> <pre><code>stack = [start_node]\nvisited = [ ]\n\nwhile (stack):\n    curr_node = stack[-1]\n    visited.append(curr_node)\n    neighbors = getNeighbors(curr_node)\n    for neighbor in neighbors:\n        if (not neighbors in visited):\n            stack.append(neighbor)\n</code></pre> <p>See also Tree#Binary Tree. </p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Graph%20Search/","title":"Graph Search","text":"<p>Breadth First Search Depth First Search [[Dynamic Programming]]</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Hash%20Map/","title":"Hash Map (Dictionary)","text":"<p>A hash map (or dictionary) is a data structure that maps keys to values. The hash map passes the key through a hash function to compute an index. That index corresponds to an array location containg a bucket from which the value can be found.</p> <p>The average lookup time complexity of a hash map is O(1).</p> <p>A hash map can be thought of as a structure on top of an array that enables the use of flexible keys instead of strictly sequential integer indices.</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Hash%20Map/#set","title":"Set","text":"<p>A set is a data structure that stores unique values without an order. A set is similar to a dictionary with only keys and no values.</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/How%20To%20Solve%20Problems/","title":"How to Solve Problems","text":"<p>A problem is defined by a set of possible inputs and their relationship to the desired output.</p> <ol> <li>Don't panic!</li> <li>What are the inputs?</li> <li>What are the outputs?</li> <li>Work through some examples by hand. What's the relationship between the inputs and outputs?</li> <li>Try and develop a simple mechanical solution (don't optimize prematurely).</li> <li>Develop incrementally, and test as you go.</li> </ol>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Linked%20List/","title":"Linked List","text":"<p>A linked list is a collection of nodes connected together via links. These nodes consist of the data to be stored and a pointer to the address of  the next node within the linked list.</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Majority%20Element%20Problem/","title":"Majority Element Problem","text":"<p>Problem</p> <p>Given an array\u00a0<code>nums</code>\u00a0of size\u00a0<code>n</code>, return\u00a0the majority element. The majority element is the element that appears more than\u00a0<code>\u230an / 2\u230b</code>\u00a0times. You may assume that the majority element always exists in the array.</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Majority%20Element%20Problem/#solution-1-map-dictionary","title":"Solution 1: Map / Dictionary","text":"<p>Use a [[Hash Table]] to store the frequency of numbers in the array. Return number with desired frequency.</p> <p>time: O(n) space: O(n)</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Majority%20Element%20Problem/#solution-2-voting-algorithm","title":"Solution 2: Voting Algorithm","text":"<p>https://www.topcoder.com/thrive/articles/boyer-moore-majority-vote-algorithm</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Tree/","title":"Tree","text":"<p>A tree is a nonlinear hierarchical data structure that consists of nodes connected by edges. A tree can be thought of as an extension of a linked list where a node can point to multiple other nodes. A tree must be connected and cannot contain any cycles, i.e., no way to reach the same node twice.</p> <p>A tree is a type of [[Graph]] with no cycles.</p> <p></p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Tree/#tree-traversal","title":"Tree Traversal","text":"<p>Traversing a tree is visiting all the nodes once. This is used for searching, inserting, and deleting nodes.</p> <p>There are two types - Depth First Search - Breadth First Search</p>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Tree/#binary-tree","title":"Binary Tree","text":"<p>A binary tree is a tree where each node has at most two child nodes.</p> <p>Depth first search for binary has three subtypes: 1. Pre-order Depth First Search     1. Visit the root     2. Traverse left subtree     3. Traverse right subtree 2. In-order Depth First Search     1. Traverse left subtree     2. Visit the root     3. Traverse right subtree 3. Post-order Depth First Search     1. Traverse left subtree     2. Traverse right subtree     3. Visit the root</p> <p>These have nice recursive implementations.</p> <pre><code>def depth_first_search(tree):\n    visit_order = list()\n    def traverse(node):\n        if node:\n            # This is pre-order\n            # swap the order to get in-order or\n            # post order\n            # visit the node\n            visit_order.append(node.get_value())\n            # traverse left subtree\n            traverse(node.get_left_child())\n            # traverse right subtree\n            traverse(node.get_right_child())\n\n    traverse(tree.get_root())\n\n    return visit_order\n</code></pre>","tags":[]},{"location":"Algorithms%20and%20Data%20Structures/Tree/#binary-search-tree","title":"Binary Search Tree","text":"<p>A binary search tree is a binary tree such that - The left subtree of a node contains only nodes with values lesser than the node\u2019s value. - The right subtree of a node contains only nodes with value greater than the node\u2019s value. - The left and right subtree each must also be a binary search tree.</p>","tags":[]},{"location":"Optimal%20Control/Dynamic%20Programming%20for%20Optimal%20Control/","title":"Dynamic Programming","text":"<p>The goal is to solve the following optimization problem,</p> <p></p> <p>The value function, or cost-to-go, is</p> \\[ \\begin{aligned}     J^*(x(t_1),t_1) = \\phi(x^*(t_f),t_f) + \\int_{t_1}^{t_f} \\ell(x^*,u^*, t)         \\mathrm{d}t. \\end{aligned} \\] <p>The optimal cost-to-go is the cost incurred from time \\(t_1\\) to \\(t_f\\) assuming optimal controls along that trajectory.  The cost-to-go obeys the Hamilton Jacobi Bellman Equation,</p> <p></p> <p>or alternatively,</p> \\[ \\begin{aligned}     0 = \\text{min}_u \\ \\left ( \\ell(x, u, t) + \\frac{\\partial J^*}{\\partial x}         f(x, u, t) + \\frac{\\partial J^*}{\\partial t}(x, t) \\right ). \\end{aligned} \\] <p>The corresponding optimal policy is</p> \\[ \\begin{aligned}     u = \\pi^*(x, t) = \\text{argmin}_u \\left ( \\ell(x, u, t) + \\frac{\\partial         J^*}{\\partial x} f(x, u, t) \\right ) \\end{aligned} \\] <p>The optimal control satisfies</p> \\[ \\begin{aligned}     \\frac{\\mathrm{d}J^*}{\\mathrm{d}t}(x,t) = - \\ell(x, u, t) \\end{aligned} \\] <p>Optimal Rate of Change of Cost-to-Go</p> <p>Under the optimal policy, the value function, or cost-to-go, decreases at a</p> <p>rate equal to the cost incurred at the current state. If the current cost is high the value function will decrease rapidly.</p> <p>This is a stricter condition than [[Lyapunov Stability]], where the Lyapunov function only needs to be strictly less than zero to guarantee asymptotic stability.</p>","tags":[]},{"location":"Optimal%20Control/Hamilton%20Jacobi%20Bellman%20Equation/","title":"Hamilton Jacobi Bellman Equation","text":"","tags":[]},{"location":"Optimal%20Control/Hamilton%20Jacobi%20Bellman%20Equation/#continuous-state-control","title":"Continuous State &amp; Control","text":"<p>The HJB equation is given by</p> \\[ \\begin{aligned}     \\frac{\\partial J^*}{\\partial t}(x, t) = - \\text{min}_u \\ \\left (         \\ell(x, u, t) + \\frac{\\partial J^*}{\\partial x} f(x, u, t) \\right ) \\end{aligned} \\] <p>^222b91</p>","tags":[]},{"location":"Optimal%20Control/Hamilton%20Jacobi%20Bellman%20Equation/#discrete-state-actions","title":"Discrete State &amp; Actions","text":"<p>Bellman Equation $$     J^(s_i) = \\text{min}_a \\left [ \\ell(s_i,a) + J^(f(s_i, a)) \\right ] $$</p> <p>Optimal policy</p> \\[ \\begin{aligned}     a = \\pi^*(s_i) = \\text{argmin}_a \\left [  \\ell (s_i,a) + J^*(f(s_i,a))         \\right ] \\end{aligned} \\] <p>The optimal policy satisfies \\(J^*(s_{i+1}) - J^*(s_i) =  - \\ell(s_i,a)\\).</p>","tags":[]},{"location":"Optimal%20Control/Hamilton%20Jacobi%20Bellman%20Equation/#value-iteration","title":"Value Iteration","text":"<p>How to find the optimal cost-to-go?</p> <p>Idea: start with estimate of the value function, \\(\\hat{J}^*(s_i) = 0\\) for all \\(s_i \\in S\\). Then iterate over</p> \\[     \\hat{J}^*(s_i) = \\text{min}_{a \\in A} [ \\ell(s_i, a)         + \\hat{J}^*(f(s_i, a))]. \\]","tags":[]},{"location":"Optimal%20Control/Optimal%20Control%20Problem%20Statement/","title":"Optimal Control Problem Statement","text":"<p>Dynamic Programming for Optimal Control</p>","tags":[]},{"location":"Optimal%20Control/Optimal%20Control%20Problem%20Statement/#continuous-time-finite-horizon","title":"Continuous Time Finite Horizon","text":"\\[ \\begin{aligned}     &amp; \\text{min}_u \\ J  = \\phi(x(t_f), t_f) + \\int_{t_0}^{t_f} \\ell(x(t), u(t),         t) \\mathrm{d}t \\\\     &amp; \\text{subject to} \\ \\dot{x} = f(x, u, t) \\end{aligned} \\] <p>^9df567</p>","tags":[]},{"location":"Optimal%20Control/Optimal%20Control%20Problem%20Statement/#discrete-time-finite-horizon","title":"Discrete Time Finite Horizon","text":"\\[ \\begin{aligned}     &amp; \\text{min}_u \\ J  = \\phi(x(N)) + \\sum_{k=0}^{N} \\ell(x(k), u(k)) \\\\     &amp; \\text{subject to} \\ x(k+1) = f(x(k), u(k)) \\end{aligned} \\]","tags":[]},{"location":"Optimal%20Control/Optimal%20Control/","title":"Optimal Control","text":"<p>%% Begin Waypoint %% - Dynamic Programming for Optimal Control - Hamilton Jacobi Bellman Equation - Optimal Control Problem Statement - References</p> <p>%% End Waypoint %%</p>","tags":[]},{"location":"Optimal%20Control/References/","title":"References","text":"<p>https://underactuated.mit.edu/</p> <p>\"Optimal Control and Estimation\" by Robert F. Stengel</p>","tags":[]},{"location":"State%20Estimation/Bayes%20Theorem/","title":"Bayes Theorem","text":"<p>Key Idea</p> <p>Bayes theorem provides a way to update a current belief given new information.</p> <p>Bayes theorem is given by, $$ \\begin{aligned}     p(h|e) = \\frac{p(h,e)}{p(e)} = \\frac{p(h) p(e|h)}{p(e)} = \\frac{p(h) p(e|h)}{p(h)p(e|h) + p(\\neg h)p(e|\\neg h)} \\end{aligned} $$</p> <p>In plain English:</p> <p>The probability of the hypothesis, h, given the evidence, e, is equal to the probability of both the hypothesis and the evidence divided by the probability of the evidence.</p> <p>Or,  $$ \\begin{aligned}     p(x|y) = \\frac{p(x,y)}{p(y)} = \\frac{p(x) p(y|x)}{p(y)} \\end{aligned} $$</p> <p>The robot has observed data y. What is the probability that the robot is at state x? This probability is equal to the likelihood of both being at state x and observing data y, divided by the total likelihood of observing y at any state.</p> <ul> <li>\\(p(x)\\) is the prior, probability of being at state \\(x\\) before incorporating the data \\(y\\).</li> <li>\\(p(y | x)\\) is the posterior probability distribution. This is the probability of observing data \\(y\\), assuming we are at state \\(x\\). This is also called the generative model, as it describes how the evolution of the state can cause sensor measurements.</li> </ul> <p>Nice video explaining Bayes Theorem:</p>"},{"location":"State%20Estimation/Clustering/","title":"K-Means Clustering","text":"<p>k-means clustering</p>","tags":[]},{"location":"State%20Estimation/State%20Estimation/","title":"State Estimation","text":"<p>Bayes Theorem [[Kalman Filter]] [[Extended Kalman Filter]] [[Unscented Kalman Filter]]</p> <p>%% Begin Waypoint %% - Bayes Theorem - Clustering</p> <p>%% End Waypoint %%</p>"}]}