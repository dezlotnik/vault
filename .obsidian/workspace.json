{
  "main": {
    "id": "4ec5180dead4adf9",
    "type": "split",
    "children": [
      {
        "id": "b4ac53215aca8815",
        "type": "tabs",
        "children": [
          {
            "id": "84684eb3b8f213be",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Reinforcement Learning/Bellman Equation.md",
                "mode": "preview",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Bellman Equation"
            }
          }
        ]
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "9db6d8701f31eba0",
    "type": "split",
    "children": [
      {
        "id": "3fa80d018cf6b4a2",
        "type": "tabs",
        "children": [
          {
            "id": "78dd719964108400",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-folder-closed",
              "title": "Files"
            }
          },
          {
            "id": "9db7ce2cdb7a2a36",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "finite",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "Search"
            }
          },
          {
            "id": "ae9536c5f04d79e8",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "Bookmarks"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 200,
    "collapsed": true
  },
  "right": {
    "id": "423cc5e87519a680",
    "type": "split",
    "children": [
      {
        "id": "feb386f64009e601",
        "type": "tabs",
        "children": [
          {
            "id": "1fb46f18e0b33bb5",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "Path Planning and Navigation/Partially Observable Markov Decision Process.md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-coming-in",
              "title": "Backlinks for Partially Observable Markov Decision Process"
            }
          },
          {
            "id": "e476317de48de691",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "Path Planning and Navigation/Partially Observable Markov Decision Process.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-going-out",
              "title": "Outgoing links from Partially Observable Markov Decision Process"
            }
          },
          {
            "id": "75a87986c1fda743",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              },
              "icon": "lucide-tags",
              "title": "Tags"
            }
          },
          {
            "id": "bfb83a21f91ded8b",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "Path Planning and Navigation/Partially Observable Markov Decision Process.md"
              },
              "icon": "lucide-list",
              "title": "Outline of Partially Observable Markov Decision Process"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false
    }
  },
  "active": "84684eb3b8f213be",
  "lastOpenFiles": [
    "Reinforcement Learning/Bellman Backup Operator.md",
    "Reinforcement Learning/Policy Iteration.md",
    "Reinforcement Learning/Policy Evaluation.md",
    "Reinforcement Learning/Markov Assumption.md",
    "Path Planning and Navigation/Markov Decision Process.md",
    "Reinforcement Learning/Bellman Equation.md",
    "Reinforcement Learning/Value Iteration.md",
    "Reinforcement Learning/Contraction.md",
    "Reinforcement Learning/Value Function.md",
    "Bellman Backup Operator.md",
    "Reinforcement Learning/Reinforcement Learning.md",
    "Optimal Control/Hamilton Jacobi Bellman Equation.md",
    "Reinforcement Learning/Q Function.md",
    "Reinforcement Learning/Stochastic Process.md",
    "Path Planning and Navigation/Path Planning and Navigation.md",
    "Reinforcement Learning/path planning.md",
    "Path Planning and Navigation/Partially Observable Markov Decision Process.md",
    "State Estimation/Bayes Filter.md",
    "State Estimation/Bayes Theorem.md",
    "Path Planning and Navigation/Discretization.md",
    "Reinforcement Learning/Temporal Difference Learning.md",
    "Algorithms and Data Structures/Tree.md",
    "Algorithms and Data Structures/Quick Sort.md",
    "Optimal Control/Dynamic Programming for Optimal Control.md",
    "Optimal Control/Optimal Control Problem Statement.md",
    "Reinforcement Learning",
    "Algorithms and Data Structures/Breadth First Search.md",
    "Path Planning and Navigation",
    "Algorithms and Data Structures/Greedy Algorithms",
    "Algorithms and Data Structures/Merge Sort",
    "Algorithms and Data Structures/Bubble Sort",
    "State Estimation",
    "Optimization",
    "Optimal Control",
    "Algorithms and Data Structures/attachments/Pasted image 20231123170734.png",
    "Algorithms and Data Structures/attachments",
    "Algorithms and Data Structures",
    "site/Algorithms and Data Structures/attachments/Pasted image 20231123170734.png",
    "docs/Algorithms and Data Structures/attachments/Pasted image 20231123170734.png",
    "docs/Algorithms and Data Structures/Pasted image 20231123170702.png",
    "docs/Algorithms and Data Structures/Pasted image 20231123170626.png",
    "site/assets/images/favicon.png"
  ]
}